# =============================================
# me.tchain.ai Backend - Environment Configuration
# =============================================

# General Settings
ENVIRONMENT=development
DEBUG=true

# API Configuration
API_HOST=0.0.0.0
API_PORT=8001
API_V1_PREFIX=/api/v1

# CORS - Comma-separated list of allowed origins
ALLOWED_ORIGINS=http://localhost:5173,http://localhost:3000

# =============================================
# Database Configuration
# =============================================
DATABASE_URL=sqlite+aiosqlite:///./data/app.db

# =============================================
# Redis Configuration (NEW - Production Features)
# =============================================
# Redis connection URL
REDIS_URL=redis://localhost:6379/0

# Enable/disable Redis for conversation storage
# If true: Uses Redis (persistent, scalable)
# If false: Uses in-memory (development only)
# Application automatically falls back to in-memory if Redis is unavailable
REDIS_USE_FOR_MEMORY=true

# =============================================
# LLM Configuration - Azure AI Foundry / DeepSeek
# =============================================
# Microsoft AI Foundry Endpoint
AZURE_AI_ENDPOINT=https://your-endpoint.inference.ai.azure.com

# API Credential (API Key)
AZURE_AI_CREDENTIAL=your_api_key_here

# API Version
AZURE_API_VERSION=2024-12-01-preview

# DeepSeek Model Configuration
DEEPSEEK_MODEL_NAME=DeepSeek-V3.2
DEEPSEEK_DEPLOYMENT_NAME=DeepSeek-V3.2

# =============================================
# LangSmith Configuration (Optional - For Tracing)
# =============================================
# Enable LangChain tracing
LANGCHAIN_TRACING_V2=true

# LangSmith API Key (get from https://smith.langchain.com/)
LANGCHAIN_API_KEY=your_langsmith_key_here

# LangSmith Project Name
LANGCHAIN_PROJECT=me-tchain-ai

# =============================================
# Contact Information
# =============================================
CONTACT_EMAIL=timucinutkan@gmail.com

# =============================================
# Production Features Configuration
# =============================================

# These features are automatically enabled and configured:
#
# 1. Rate Limiting
#    - 100 requests per minute per IP (configurable in app/core/rate_limit.py)
#    - ASGI middleware for high performance
#    - Automatic proxy support (X-Forwarded-For)
#
# 2. Circuit Breaker
#    - LLM: 5 failures → 60s recovery
#    - Redis: 3 failures → 30s recovery
#    - Automatic retry with exponential backoff
#
# 3. WebSocket Connection Management
#    - Per-client limit: 5 concurrent connections
#    - Total server limit: 1000 connections
#    - TTL: 1 hour idle timeout
#    - Heartbeat: 30 second ping/pong
#
# 4. Conversation Storage
#    - Redis: Persistent, scalable (if REDIS_USE_FOR_MEMORY=true)
#    - In-memory: Development fallback (if REDIS_USE_FOR_MEMORY=false)
#    - TTL: 1 hour per conversation
#    - Max history: 20 messages per conversation
#
# No additional configuration required!
# See IMPROVEMENTS_IMPLEMENTED.md for details.
